"""
Demonstration Script for DQN Learning Process
Shows the agent learning to solve the STA83 exam timetabling problem
"""
import numpy as np
from environment import ExamTimetablingEnv
from agent import DQNAgent

def demonstrate_learning_process():
    """Demonstrate the DQN learning process with detailed output"""
    print(" DQN Learning Demonstration for STA83 Exam Timetabling")
    print("="*60)
    
    # Create environment
    print("\n🏗 Setting up environment...")
    env = ExamTimetablingEnv(max_timeslots=15)
    
    # Create agent
    print("\n Creating DQN agent...")
    state_size = env.observation_space.shape[0]
    action_size = env.action_space.n
    
    agent = DQNAgent(
        state_size=state_size,
        action_size=action_size,
        learning_rate=0.001,
        epsilon_start=1.0,
        epsilon_end=0.1,
        epsilon_decay=0.99,  # Faster decay for demo
        batch_size=16,       # Smaller batch for demo
        target_update_freq=50
    )
    
    print(f"   State size: {state_size}")
    print(f"   Action size: {action_size}")
    print(f"   Device: {agent.device}")
    
    # Demonstrate learning over episodes
    print(f"\n🎮 Training demonstration (50 episodes)...")
    
    successful_episodes = 0
    best_reward = -float('inf')
    best_timeslots = float('inf')
    
    for episode in range(50):
        state = env.reset()
        episode_reward = 0
        episode_length = 0
        valid_solution = False
        
        # Run episode
        for step in range(env.num_exams):
            valid_actions = env.get_valid_actions()
            
            if not valid_actions:
                break
                
            action = agent.act(state, valid_actions)
            next_state, reward, done, info = env.step(action)
            
            # Store experience
            agent.remember(state, action, reward, next_state, done)
            
            # Train if enough experiences
            if len(agent.replay_buffer) >= agent.batch_size:
                agent.replay()
            
            state = next_state
            episode_reward += reward
            episode_length += 1
            
            if done:
                if 'valid_solution' in info and info['valid_solution']:
                    valid_solution = True
                    successful_episodes += 1
                    solution_quality = env.get_solution_quality()
                    timeslots_used = solution_quality['timeslots_used']
                    
                    if episode_reward > best_reward:
                        best_reward = episode_reward
                    if timeslots_used < best_timeslots:
                        best_timeslots = timeslots_used
                break
        
        # Print progress every 10 episodes
        if (episode + 1) % 10 == 0:
            success_rate = successful_episodes / (episode + 1)
            print(f"\nEpisode {episode + 1}/50:")
            print(f"  Success Rate: {success_rate:.3f}")
            print(f"  Epsilon: {agent.epsilon:.3f}")
            print(f"  Buffer Size: {len(agent.replay_buffer)}")
            print(f"  Best Reward: {best_reward:.2f}")
            if best_timeslots < float('inf'):
                print(f"  Best Timeslots: {best_timeslots}")
    
    # Final evaluation
    print(f"\n🔍 Final evaluation (10 episodes)...")
    eval_stats = agent.evaluate(env, num_episodes=10)
    
    print(f"\n DEMONSTRATION RESULTS")
    print(f"="*40)
    print(f"Training Success Rate: {successful_episodes/50:.3f}")
    print(f"Evaluation Success Rate: {eval_stats['success_rate']:.3f}")
    
    if eval_stats['solutions']:
        print(f"Average Timeslots Used: {eval_stats['avg_timeslots']:.1f}")
        print(f"Average Proximity Penalty: {eval_stats['avg_proximity_penalty']:.2f}")
        
        best_solution = min(eval_stats['solutions'], key=lambda x: x['timeslots_used'])
        print(f"Best Solution: {best_solution['timeslots_used']} timeslots")
        print(f"Best Proximity Penalty: {best_solution['avg_proximity_penalty']:.2f}")
    
    # Show learning insights
    print(f"\n🧠 LEARNING INSIGHTS")
    print(f"="*40)
    print(f"1. The agent started with random exploration (epsilon=1.0)")
    print(f"2. Through experience replay, it learned to avoid clashes")
    print(f"3. Action masking ensured only valid moves were selected")
    print(f"4. The reward structure guided it toward better solutions")
    
    if eval_stats['success_rate'] > 0.5:
        print(f" The agent successfully learned to create clash-free timetables!")
    else:
        print(f"⚠ The agent needs more training to consistently solve the problem")
    
    return eval_stats

def show_solution_example():
    """Show an example of a solution generated by the trained agent"""
    print(f"\n SOLUTION EXAMPLE")
    print(f"="*40)
    
    env = ExamTimetablingEnv(max_timeslots=15)
    agent = DQNAgent(
        state_size=env.observation_space.shape[0],
        action_size=env.action_space.n,
        epsilon_start=0.0  # No exploration for demonstration
    )
    
    # Generate a solution
    state = env.reset()
    solution_steps = []
    
    for step in range(env.num_exams):
        valid_actions = env.get_valid_actions()
        if not valid_actions:
            break
            
        action = agent.act(state, valid_actions)
        next_state, reward, done, info = env.step(action)
        
        exam_id = step + 1
        timeslot = action + 1
        solution_steps.append((exam_id, timeslot, reward))
        
        state = next_state
        
        if done:
            break
    
    # Show first 10 assignments
    print(f"First 10 exam assignments:")
    for i, (exam_id, timeslot, reward) in enumerate(solution_steps[:10]):
        print(f"  Exam {exam_id:3d} → Timeslot {timeslot:2d} (reward: {reward:6.2f})")
    
    if len(solution_steps) > 10:
        print(f"  ... and {len(solution_steps) - 10} more assignments")
    
    # Show final solution quality
    if done and 'valid_solution' in info and info['valid_solution']:
        quality = env.get_solution_quality()
        print(f"\n Complete solution generated!")
        print(f"   Total timeslots used: {quality['timeslots_used']}")
        print(f"   Average proximity penalty: {quality['avg_proximity_penalty']:.2f}")
    else:
        print(f"\n Solution incomplete or invalid")

if __name__ == "__main__":
    # Run demonstration
    eval_stats = demonstrate_learning_process()
    
    # Show solution example if agent learned successfully
    if eval_stats['success_rate'] > 0:
        show_solution_example()
    
    print(f"\n Demonstration completed!")
    print(f"For full training, run: python train_dqn_sta83.py") 